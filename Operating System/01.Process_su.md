# 01. Process

## Process
어떻게 다수의 CPU 상에서 동작하는 것처럼 보이게 할까?

시분할(time sharing) : 하나의 프로세스를 실행하다 얼마 후 중단시키고 다른 프로세스를 실행하는 작업을 반복하면서 단일 또는 소수의 CPU로 그보다 많은 CPU가 존재하는 듯한 환상을 만들어냄. 결과적으로 여러 프로세스를 동시에 실행하는 것처럼 만듬. 단, CPU를 공유하기 때문에, 각 프로세스의 성능은 낮아짐.

공간 분할(space sharing) : 시분할에 대응되는 개념. (e.g. 메모리를 여러 프로세스가 공유, 하드디스크 공간을 여러 파일들이 공유)

### Mechanism vs. Policy
다수의 운영체제의 공통된 설계 패러다임 중 하나는 고수준 policy을 저수준 mechanism으로부터 분리하는 것. 간단하게 mechanism은 '어떻게'에 대한 답이며, policy는 '어느 것'에 대한 답. 이는 모듈성의 한 형태로, policy를 변경할 때 mechanism의 변경을 고민할 필요가 없게 만듬.

#### Mechanism
필요한 기능의 일부를 구현하는 저수준의 방법이나 프로토콜로 정해진 절차에 따라 단순하고 고정적으로 결과를 내는 저수준의 기계적인 절차를 의미함. 여기에는 새로운 생각이 들어갈 여지가 없음. (e.g. context switching).

#### Policy
운영체제에서 일종의 결정을 내리는 고수준의 알고리즘. 관점에 따라 장단을 다툴 여지가 있는 문제를 처리하는 것은 policy로 봄 (e.g. scheduling policy).

**scheduling policy** : 간단하게 프로세스에게 효율적으로 자원을 할당하기 위한 정책. 아래는 기준.
- historical information
- workload knowledge
- performance matrics

### Process의 개념
운영체제가 실행 중인 프로그램이라는 개념을 제공하기 위한 추상화의 일종.

프로세스가 실행되는 동안의 특정한 순간마다 프로세스가 접근했거나 영향을 미친 시스템의 다양한 자원에 대한 목록으로 프로세스를 요약할 수 있음. 이러한 목록을 machine state라 부름.

#### 대표적인 machine state 요소
- address space : 운영체제가 독립적으로 할당해서 준 메모리의 특정 영역에 대한 주소
- register : 명령어가 처리될 때의 CPU 상태 (e.g. program counter, stack pointer, frame pointer)
- I/O Information : 프로세스가 현재 열어 놓은 파일 목록.

### Process API
운영체제는 많은 프로세스 API를 제공. 아래는 필히 API로 제공해야만 하는 기본 기능.
- Create : 새로운 프로세스 생성.
- Destroy : 프로세스를 강제로 제거.
- Wait : 프로세스의 실행이 중지될 때까지 대기.
- Status : 프로세스의 status 정보 확인.
    - state vs. status
        - state : 보다 본질적인 것 (The overall physical condition of something; the ability of something to be used, enjoyed, etc).
        - status : state의 일부를 관찰하는 하는 상황을 전제로 사용 (the current state of someone or something).
- 각종 control : 프로세스의 중지, 재개 등.

#### Process 생성
어떻게 프로그램을 준비시키고 실행하는가? 어떻게 프로세스를 생성하는가?

1. 보조기억장치에 실행 파일 형식으로 저장된 프로그램을 메모리 공간(프로세스의 주소 공간)에 load.
    - eager loading : 프로그램을 실행시키기 전에 프로그램 전부를 로딩. 일단 실행된 이후에는 디스크가 프로그램 실행에 개입하지 않음 (즉, 프로그램이 빠르게 실행됨).
    - lazy loading : 코드 또는 데이터의 일부만 필요한 경우에 로딩. 실행되지 않는 부분은 loading하지 않을 수 있음.
1. 프로그램의 stack을 위한 메모리 영역을 할당.
1. 프로그램의 heap을 위한 메모리 영역을 할당.
1. 입출력과 관계된 초기화 작업을 수행.
1. entry point로 분기.
1. 운영체제는 CPU를 새로 생성된 프로세스에 넘김.

#### Process State
프로세스는 아래 세 상태 중 하나에 존재할 수 있음.
- Running : 프로세서에서 실행 중인 상태.
- Ready : 실행 할 준비는 되어 있지만, 운영체제가 다른 프로세스를 실행하는 등의 이유로 대기 중인 상태.
- Blocked : 프로세스가 다른 사건을 기다리는 동안 프로세스의 수행을 중단 중인 상태. 다른 프로세스가 Running이 될 수 있음.

### 자료 구조
운영체제는 앞의 개념을 구현하기 위해 여러 자료 구조를 갖고 있음.

```c
// 프로세스를 중단하고 이후에 재개하기 위해 저장하고 복원하는 레지스터􏰈􏰉􏰊 􏰋􏰌
 struct context { // 운영체제가 32bit임을 알 수 있음.
    int eip;
    int esp;
    int ebx;
    int ecx;
    int edx;
    int esi;
    int edi;
    int ebp;
};

// 가능한 프로세스 􏰝􏰞
enum proc_state { UNUSED, EMBRYO, SLEEPING,
RUNNABLE, RUNNING, ZOMBIE };
􏰉􏰗 􏰩􏰪
// 레지스터 context와 프로세스 state를 포함하여 각 프로세스에 대해 xv6가 추적하는 정보.
struct proc {
    char *mem;
    uint sz;
    char *kstack;
    enum proc_state state; // 프로세스 state. 위에 열거형으로 정의됨.
    int pid;
    struct proc *parent;
    void *chan;
    int killed;
    struct file *ofile[NOFILE];􏱁􏱂 􏱃􏱄
    struct inode *cwd; 􏱆􏱇􏰚􏰭
    struct context context; // 프로세스가 정지된 상태가 되면 이의 내용을 여기에 저장.
    struct trapframe *tf;
};
```

## Limited Direct Execution
### CPU 가상화를 위해 해결해야 할 문제
1. Performance : 성능 저하 문제
1. Control : 제어 문제

즉, 제어를 유지하면서 효과적으로 CPU를 가상화하려면 어떻게 해야하는지가 관건. 둘 중 하나를 배제하면 안 되고, 모두를 적절히 지원해야 하는데 이를 위해선 하드웨어와 운영체제가 협업해야 함.

### Direct Execution
#### 개념
프로그램을 CPU 상에서 직접 실행시키는 것.

#### 고려 사항
1. 운영체제가 원치 않는 일을 프로그램이 하지 않을 것을 보장할 수 없음.
1. 프로세스 실행 중에 운영체제가 해당 실행을 중단하고 타 프로세스로 전환할 수단이 필요함 (= 시분할 기법 구현 방법이 필요함).

direct execution을 사용하면 성능 측면에서는 우수하겠지만, 운영체제가 프로세스를 제어할 수 없음. 그래서 limited direct execution이 나옴.

### Limited Direct Execution
#### 첫 번째 문제 : 
**문제 상황 정리** : I/O나 제한된 명령을 프로세스가 수행할 수는 있어야 하지만, 해당 프로세스가 시스템에 대한 제어를 탈취하는 것은 막아야 함.

**문제 해결 방안** : 명령어 집합을 구분하고 유저 모드와 커널 모드로 나눠 유저 모드에서는 privileged operation에 접근하는 것을 막아야 함. 구체적으로는 이들 명령어를 유저 모드에서 실행하려 하면 프로세서가 예외를 발생시키고, 운영체제가 이를 캐치해서 프로세스를 kill (규제 위반 확인 : 하드웨어 / 규제 실행 : 운영체제). 또한, system call을 제공해 제한적으로 프로세스가 I/O 등의 기능을 이용할 수 있도록 설계.

**System Call (syscall)** : 프로세스가 운영체제에게 서비스를 요청하는 것을 말함. 이는 프로세스와 운영체제 간 필적인 인터페이스를 제공.

**System Call의 개략적인 동작 순서** : <br>
프로세스가 trap 특수 명령어를 실행(procedure call에서의 jmp나 call같은 애) <br>
  -> 프로세스에서 커널 내부 코드로 분기. 특권 수준을 kernel mode로 상향 조정 <br>
  -> 프로세스가 요청한 작업을 운영체제가 처리 <br>
  -> 운영체제는 return-from-trap 특수 명령어를 사용해 특권 수준을 다시 user mode로 하향 조정. 호출한 사용자 프로세스로 리턴.

**Trap Table** : 
- 존재 이유 : jxx나 call 등의 명령어는 직접 주소를 명시하지만, trap은 그것이 별로 바람직하지 않아서 (주소를 오버라이팅 하면 임의 주소로의 분기가 가능하기 때문에).
- 형태 : 부팅을 하면 kernel이 첫 열은 번호, 두 번째 열은 번호에 해당하는 trap handler의 주소로 표를 작성함. 프로세스 뿐만 아니라 하드웨어에서도 사용 가능.

#### 두 번째 문제
두 번째 문제 해결(프로세스 간 전환) :
운영체제는 실행 중인 프로세스를 계속 실행할 것인지 다른 프로세스를 실행할 것인지 결정해야 함. 여기에는 2가지 문제가 있음. 1. 판단 기준 2. 프로세스가 실행 중이라는 것은 운영체제는 실행 중이지 않다는 것인데 어떻게 전환?
**문제 상황 정리** : 운영체제는 현재 실행 중인 프로세스를 계속 실행할 것인지 다른 프로세스를 실행할 것인지 결정해야 하지만, 2가지 문제가 있음.
1. 운영체제의 실행 (프로세스가 실행 중이라는 얘기는 운영체제는 실행 중이지 않다는 것)
2. 판단 기준 (계속 할지 말지에 대한 기준)

**운영체제의 실행 해결** : 협조 방식과 비협조 방식이 존재.
- 협조 방식 : 너무 오랫동안 실행할 가능성이 있는 프로세스는 운영체제가 다른 작업을 할 수 있도록 주기적으로 CPU를 포기할 것이라 가정.
- 비협조 방식 : 타이머 인터럽트를 이용해 수 밀리초마다 인터럽트를 발생시키고 운영체제는 CPU 제어권을 다시 얻게 됨. 인터럽트라고 하는 것이 누가 어떻게 만드는지를 알아야 그림이 그려질 것 같은데. 그런 식으로 타이머가 동작하려면 하드웨어여야 됨. 안 그러면 어차피 CPU는 누군가가 혼자 쓰니까

**판단 기준 해결** :
스케쥴러가 이 부분을 판단함. 전환이 결정되면 문맥 교환 코드를 실행. 단순하게는 현재 실행 중인 프로세스의 레지스터 값을 따로 저장하고 실행시킬 프로그램의 레지스터 값을 복원.

**궁금한 점** : 유저모드와 커널모드가 하드웨어 단에서 제공했던 거야? 모드가 커널인지 유저인지 어떻게 알고 하드웨어 단에서 확인해 예외를 발생시키는거야?
어떻게 trap table이 하드웨어에서도 사용이 가능해? 커널도 프로세스인데 프로세스에서 세팅해준 정보를 하드웨어에서 사용 가능해?
trap table에 있는 주소를 오버라이트하면 되는거 아니야? 그걸 못 할 이유가 있어?

## CPU Scheduling
스케줄링 정책은 어떻게 개발하는가?

### Scheduling Metric
scheduling 결과를 비교하기 위한 정량적 지표.

#### Turnaround Time
얼마나 빠르게 작업을 마치는지에 대한 지표.

$T_{turnaround}=T_{completion}-T_{arrival}$
- $T_{completion}$ : 작업이 완료된 시각.
- $T_{arrival}$ : 작업이 시스템에 도착한 시각.

#### Response Time
얼마다 빠르게 작업에 대해 응답을 시작하는지에 대한 지표.

$T_{response}=T_{firstrun}-T_{arrival}$
- $T_{firstrun}$ : 작업이 처음 스케줄 된 시각.
- $T_{arrival}$ : 작업이 시스템에 도착한 시각.

### Non-preemptive vs. Preemptive

#### Non-preemptive Scheduling
job이 일단 CPU를 할당받으면, 종료 후 반환 시까지 다른 job은 CPU 점유가 불가능한 scheduling.

#### Preemptive Scheduling
현재 실행 중인 job을 중단시키고 scheduler가 준비 중인 job 중 하나를 실행시킬 수 있는 scheduling.


### FIFO(First In, First Out) Scheduling
#### 동작
간단하게 가장 먼저 도착한 job부터 먼저 실행.

#### 가정
- 모든 작업은 같은 시간 동안만 실행됨.
- 모든 작업은 시스템에 동시에 도착.
- 각 작업은 시작되면 완료 시까지 실행됨.
- 모든 작업은 CPU만을 사용 (I/O 작업을 수행하지 않음).
- 각 작업의 실행 시간은 사전에 알려져 있음.

#### 장점
- 극히 간단하고 직관적. queue 하나만 만들어서 간단하게 구현할 수 있음.
- 위의 가정이 모두 참이라고 하면, 자못 잘 동작함.

**예시 1** :
세 개의 job A, B, C가 동시에 시스템에 도착했고, 각 job은 모두 10초 동안 동작한다고 가정하자. 이때 평균 turnaround time은 ${10 + 20 + 30 \over 3}=20$ 이 되게 됨. A, B, C의 순서대로 동작했다고 하면, A는 10초, B는 A가 끝나고 10초동안 동작하므로 20초, C도 같은 이유에서 30초가 되기 때문.

#### 단점
- 가정1(모든 작업은 같은 시간 동안만 실행됨)이 참이 아니면, 상당히 비효율적.
    - Convoy Effect : 상대적으로 가벼운 자원 소비자들이 무거운 자원 소비자 뒤에 대기열을 형성하는 상황. 컴퓨터 네트워크에서는 HoL(Head-Of-Line) Blocking이라고 함.

**예시 2** : A, B, C의 순서대로 실행이 되는데 동작 시간이 A가 200초, B가 10초, C가 15초라고 하면, B, C는 10초, 15초 밖에 되지 않음에도 불구하고 A의 200초를 기다려야 함. 이는 평균 turnaround time을 괜히 증가만 시킴. 평균 turnaround time : ${200 + 210 + 225 \over 3}=211.\dot 6$

### SJF(Shortest Job First) Scheduling
#### 동작
평균 turnaround time을 최소화하기 위해 CPU 점유 시간이 가장 짧은 순서로 SJF scheduler는 실행 대상을 선택.

#### 가정
- ~~모든 작업은 같은 시간 동안만 실행됨.~~
- 모든 작업은 시스템에 동시에 도착.
- 각 작업은 시작되면 완료 시까지 실행됨.
- 모든 작업은 CPU만을 사용 (I/O 작업을 수행하지 않음).
- 각 작업의 실행 시간은 사전에 알려져 있음.

#### 장점
- 남아있는 가정 하에서 이 알고리즘이 최적이라는 것을  증명할 수 있음 (절대로 SJF가 만든 결과보다 더 나은 turnaround time을 갖는 알고리즘은 존재하지 않음).

**예시 3** : A, B, C의 순서대로 실행이 되는데 동작 시간이 A가 200초, B가 10초, C가 15초라고 하자. B가 가장 짧기 때문에 B가 먼저 실행되고, 다음에 C, A가 차례로 실행. 평균 turnaround time : ${10 + 25 + 225 \over 3} = 86.\dot 6$

#### 단점
- 가정2(모든 작업은 시스템에 동시에 도착)가 참이 아니면, 의미가 없음. 예시 3에서는 A, B, C가 동시에 시스템에 도착했기 때문에 평균 turnaround time이 대략 86초가 나왔지만, 만약 job A가 B 또는 C보다 먼저 도착하게 되면 job A가 먼저 실행이 되면서 B, C는 200초 이상의 시간을 온전히 기다려야 함.

**예시 4** : A, B, C의 순서대로 실행이 되는데 동작 시간이 A가 200초, B가 10초, C가 15초라고 하자. A가 도착하고 10초 뒤에 B와 C가 도착했다고 하면, 평균 turnaround time은 ${200 + (210 - 10) + (225 - 10) \over 3}=205$ 가 됨. 예시 2의 211과 큰 차이가 없음.

### STCF(Shortest Time-to-Completion) Scheduling
#### 동작
 특정한 job이 시스템에 도착했을 때마다 STCF scheduler는 새로운 job을 포함해 각 job의 잔여 실행 시간을 계산하고 이것이 가장 작은 job을 실행.

#### 가정
- ~~모든 작업은 같은 시간 동안만 실행됨.~~
- ~~모든 작업은 시스템에 동시에 도착.~~
- ~~각 작업은 시작되면 완료 시까지 실행됨.~~
- 모든 작업은 CPU만을 사용 (I/O 작업을 수행하지 않음).
- 각 작업의 실행 시간은 사전에 알려져 있음.

두 번째 가정을 완화하기 위해 세 번째 가정을 완화. 세 번째 가정이 완화되면, 임의의 job이 실행되는 중에 중지되고 이와 다른 job이 실행되는 것이 가능.

#### 장점 
- 남아있는 가정 하에서 최적임을 증명할 수 있음.

**예시 5** : A, B, C의 순서대로 실행이 되는데 동작 시간이 A가 200초, B가 10초, C가 15초라고 하자. A가 도착하고 10초 뒤에 B와 C가 도착했다고 하면, A는 남은 실행 시간이 190초이고 B는 10초, C는 15초이므로, A가 중단되고, B로 실행이 넘어감. B가 실행을 마치면, C가 실행되고 마지막으로 남은 A가 실행됨. 평균 turnaround time은 ${(225 - 0) + (20 - 10) + (35 - 10) \over 3}=86.\dot6$ 가 됨. 예시 2의 211과 큰 차이가 없음.

#### 단점
사용자가 터미널과 상호작용을 하게 되면서 turnaround time보다는 response time이 중요해짐. STCF의 경우 turnaround time은 훌륭하지만, response time이 짧다고는 말할 수 없음.

### RR(Round-Robin) Scheduling
#### 동작
작업이 끝날 때까지 기다리지 않고, scheduling quantum이 끝나면 실행 큐의 다음 작업으로 실행을 전환.
- scheduling quantum(= time slice) : 작업이 실행되는 일정한 시간 단위. 타이머 인터럽트를 트리거로 하여 다음 작업으로 전환하기 때문에, 이 시간은 타이머 인터럽트 주기의 배수여야 함.

scheduling quantom의 길이가 중요함. 길이가 짧아지면 그만큼 response time은 줄어들겠지만, context switching 비용이 전체 성능에 큰 영향을 미치게 됨.

#### 장점
STCF scheduling에 비해 response time이 빠를 수밖에 없음.

**예시 6** : job A, B, C가 동시에 도착했고, 각각은 실행 시간이 200초, 10초, 15초라고 하자. time slice가 1초라고 하면 평균 responce time은 ${0 + 1 + 2 \over 3}=1$

#### 단점
상술한 것처럼 길이가 짧아지면 response time은 줄지만 context switching 비용이 성능에 영향을 많이 미치게 되고 그것이 아니더라도 하나의 작업에 대한 turnaround time은 확실히 STCF보다 길어질 수 밖에 없음 (정도가 아니고 FIFO보다 최악임).

### 입출력에 대한 고려
실행 중이던 job이 입출력 요청을 발생시키면, 해당 job은 입출력이 완료될 때까지 CPU를 사용하지 않을 것이기 때문에 스케줄러는 다음에 어떤 작업을 실행할지 결정해야됨. 그 시간동안 CPU를 놀리는 것은 상당히 비효율적.

#### 가정
- ~~모든 작업은 같은 시간 동안만 실행됨.~~
- ~~모든 작업은 시스템에 동시에 도착.~~
- ~~각 작업은 시작되면 완료 시까지 실행됨.~~
- ~~모든 작업은 CPU만을 사용 (I/O 작업을 수행하지 않음).~~
- 각 작업의 실행 시간은 사전에 알려져 있음.

### MLFQ(Multi-Level Feedback Queue) Scheduling
#### 정리 & 배경
가정 1 ~ 3만 거짓이라 했을 때, STCF는 turnaround time이 가장 짧았지만 response time이 길었고, RR은 반대로 response time은 가장 짧았지만, turnaround time은 간단한 FIFO 보다도 길었음.

이러한 상황에서, 작업의 실행 시간에 대한 선행 정보 없이(가정 5가 참이 아님) 대화형 작업의 response time을 최소화하고, 동시에 turnaround time 또한 최소화하는 scheduler를 어떻게 설계할 수 있을까?

#### 가정
- ~~모든 작업은 같은 시간 동안만 실행됨.~~
- ~~모든 작업은 시스템에 동시에 도착.~~
- ~~각 작업은 시작되면 완료 시까지 실행됨.~~
- ~~모든 작업은 CPU만을 사용 (I/O 작업을 수행하지 않음).~~
- ~~각 작업의 실행 시간은 사전에 알려져 있음.~~

#### 구성
서로 다른 우선순위(priority level)를 갖는 여러 개의 queue로 구성. 최상위 queue가 가장 우선순위가 높고 아래로 갈수록 우선순위가 낮아짐. queue에는 둘 이상의 job이 존재할 수 있음. 실행 준비가 된 job은 이들 중 하나에 위치함.

#### 동작
관찰된 job의 행동을 바탕으로 MLFQ는 해당 job의 우선순위를 정함. 즉, 과거의 행동에 기반해 job의 미래의 행동을 예측함.
- job이  CPU를 I/O 등을 이유로 반복적으로 양보하면 높은 우선순위를 부여.
- job이 CPU를 집중적으로 사용하면 낮은 우선순위를 부여.

이때, 

MLFQ가 동작하는 규칙은 아래와 같음. 
1. job A가 job B보다 높은 우선순위를 가질 경우, A가 실행되며, B는 실행되지 않음.
1. job A와 job B가 우선순위가 같을 경우, A와 B는 RR 방식으로 실행됨.
1. job이 시스템에 들어가면 최상위 queue(가장 우선순위가 높은 queue)에 배치.
    - scheduler는 각각의 job이 짧은 실행 시간을 갖는지 아닌지 알 수 없으므로, 최상위 queue에 배치. 만약 짧은 job이 아니라면 한 단계씩 아래 queue로 내려가면서 자신이 짧지 않음을 증명하게 됨.
1. job이 지정된 단계에서 배정받은 시간을 소진하면, CPU를 포기한 횟수와는 상관없이 job의 우선순위가 감소함(즉, 한 단계 아래 queue로 이동).
    - 주어진 time slice를 모두 사용하면 우선순위가 낮아지고, 모두 사용하기 전에 CPU를 양도하면 유지되는 방식은 time slice가 끝나기 직전에 CPU를 양도하는 식으로 scheduler가 자신에게 유리하도록 프로그램을 작성할 소지가 있음. 따라서 배정받은 시간을 모두 소진하면 job의 우선순위를 감소시키는 것으로 배정된 시간보다 많은 시간을 사용할 수 없도록 해야함.
1. 일정 주기가 지난 후, 시스템의 모든 작업을 최상위 queue로 이동시킴 (boost).
    1. 기아 문제 해결 : 최상위 queue에 존재하는 동안에는 같은 위치의 다른 job들과 RR 방식으로 CPU를 공유하기 때문에 다수의 대화형 작업이 존재하는 상황에서도 실행을 보장받음.
    1. 변화하는 job의 특성 반영 : 특성이 변해도 낮은 우선순위에 있었다면 높은 우선순위로 갈 수 없었지만, 주기적으로 시스템의 모든 작업을 최상위로 이동시킴으로써 변경된 특성에 적합한 방법을 적용할 수 있음.

#### 주의
job이 행동 단계를 갖고 있고 따라서 예측할 수 있을 때 효과가 있음. 쉽게 틀릴 수도 있고, 아무런 지식이 없이 행동하는 것보다 더 좋지 않은 상황을 만들 수도 있음.

구현과 관려된 구체적인 숫자(queue의 개수, queue 당 time slice 크기, boost 주기 ...)를 확답할 수 없음.

### Proportional Share Scheduler
지금까지의 평가 지표였던 turnaround time 또는 response time에 대한 최적화 대신에 scheduler가 각 작업에게 CPU의 일정 비율을 보장하는 것이 목적.

특정 비율로 CPU를 배분하는 스케줄러를 어떻게 설계할 것인가? 그렇게 하기위한 주요 메커니즘은 무엇인가? 그 메커니즘은 얼마나 효과적인가?

#### Lottery Scheduling
**ticket** : job(또는 user나 group. 이후에는 편의를 위해 job으로 한정)이 받아야 할 자원의 몫을 나타내는 지표로 사용. 특정 job의 소유한 ticket 개수의 전체 ticket 개수에 대한 비가 곧 해당 job의 몫.

예를 들어, job A, B가 있다고 할 때, A가 75장의 ticket을 B가 25장의 ticket을 갖고 있으면, 75%의 CPU를 A에게, 25%의 CPU를 B에게 할당하는 것.

이러한 개념은 CPU sheduling에서 뿐만 아니라 hyperviser가 virtual memory를 관리하는 상황 등 공유 자원에 대한 지분을 나타낼 때도 이용될 수 있음.

**ticket 구성** : 
- 해당되는 job
- 고유 번호

**진행** : 
1. scheduler는 전체 몇 장의 ticket이 있는지 알아야 함.
1. 비복원 추출을 통해 한 장을 선택.
    - 이러한 작업은 매 time slice와 같이 일정한 주기를 갖고, 매우 빈번하게 발생.
1. 선택된 ticket의 값에 따라 실행될 job이 결정.
1. scheduler는 이를 실행.

**random의 장점** :
- 쉽게 corner-case behavior를 피할 수 있음. 일반적으로 잘 동작한다고 알려진 policy도 특정한 상황에서는 성능에 부정적 영향을 끼칠 수 있지만, random은 그럴 일이 없음.
- 정보를 많이 저장할 필요가 없음. 앞의 scheduling policy만 봐도 각 job의 CPU 사용량을 기억해야 하고, 각 job의 사용이 끝날 때마다 이를 갱신해야 하지만, random은 그에 비해 저장할 정보가 적음.
- random은 상당히 빠를 수도 있음. random은 빠르게 만들 수는 있지만, 빠르게 만들면 만들수록 sudo-random에 가까워짐.

**추첨 mechanism** : 
- ticket currency : 시스템이 자신의 하위 그룹에게 추첨권을 나눠줬을 때 해당 하위 그룹은 자신만의 화폐 가치로 추첨권을 자유롭게 할당할 수 있음. 시스템은 다시 자신의 화폐가치로 이를 자동적으로 변환.
    - 구체적인 방식이 궁금한데 시스템이 자동적으로 변환할 때 정수로 떨어지지 않도록 하위 그룹에서 분배가 가능한지. 사실 이게 허용이 안 되면 큰 의미가 있나 싶은데 모르겠네
- ticket transfer : job은 일시적으로 자신의 ticket을 다른 job에게 양도할 수 있음. 웹서버와 DB서버를 생각할 때, DB서버에서 작업을 마쳐야만 웹서버가 추가적인 작업을 진행할 수 있다면 웹서버는 DB서버에게 자신의 ticket 중 일부를 잠시 양도하여 효율을 높일 수 있음.
- ticket inflation : job 간 상호 경쟁이 없는 상황에 한정해서 job은 시스템에 이를 알리는 식으로 일시적으로 자신이 소유한 ticket의 수를 다른 job과 통신하지 않고 늘리거나 줄일 수 있음.
    - 이게 어떻게 가능한가. ticket에는 해당되는 job과 고유번호가 있는데. 그럼 전체 시스템의 ticket 수를 임시로 늘리는거야? 추첨권의 가치를 상향조정하는 것도 어떻게?????

**구현** :
```c
int counter = 0; // 난수가 특정 job의 ticket 번호 안쪽인지 확인하기 위해 사용

int winner = get_random(0, totaltickets); // 0에서 총 추첨권 수 사이의 난수 생성

node_t * current = head; // job 목록 탐색을 위한 pointer

while (current) { // current가 NULL이 아니면(노드가 끝이 아니면) 실행
    counter += current->tickets; // counter에 해당 job의 ticket 개수 더함

    if (counter > winner) { // 더한 값이 난수보다 크다는 것은 난수가 해당 job의 ticket 범위 내에 있다는 것
        break;
    }

    current = current->next; // 다음 job으로 이동
}
```

sudo code이긴 해도 구현을 이렇게 하면 복원 추출인데 예시도 복원 추출이었고 교수님은 비복원 추출이라 하는데(교수님이라기 보다는 출판사에서 만들어준 ppt) 뭐가 맞는거야? 비복원 추출이 구현이 쓸데 없이 복잡해지긴 해...;;

**단점** : 비율에 맞게 ticket을 배분하더라도 우리의 예상과 동작은 다소 다를 수 있음.

두 개의 job A, B가 모두 100개의 ticket을 갖고 있고, 실행 시간이 R로 같다고 하자.

이러면 거의 동시에 끝날 것을 기대하지만, randomness에 의해 한 job이 다른 job보다 먼저 끝날 수 있음.

불공정 지표 : 첫 job이 종료된 시각을 두 번째 job이 종료된 시각으로 나눈 값. 1에 가까울 수록 공정.

실행 시간이 증가할수록 공정해지는 것을 확인할 수 있음.

2 추첨권 배분 방식
주어진 job 집합에 대한 추첨권 할당 문제는 미해결.

**결정론적 방법을 사용하지 않는 이유** : 결정론적 방법은 정확한 비율로 CPU를 배분하고 예상과 보다 잘 맞는 실행을 보여줄 수는 있지만, 상태 정보가 필요하고 새로운 job에 대한 보다 복잡한 고려가 필요함. 하지만, lottery schceduling은 상태 정보 저장이 필요하지 않고, 새로운 job에 대해서도 새 job이 가진 ticket의 개수, 전체 ticket의 개수만 갱신하고 스케줄할 수 있으므로 상당히 가볍고 단순함.

### Multiprocessor scheduling
운영체제는 어떻게 여러 CPU에 job을 스케줄 해야 하는가? 어떤 새로운 문제가 등장하는가? 예전 기술을 적용할 것인가 아니면 새로운 아이디어가 필요한가?

#### Multiprocessor System vs. Multicore System
**multiprocessor system** : 여러개의 독립적인 processor가 시스템 내에 존재.
**multicore system** : 여러개의 CPU core가 하나의 칩 내에 존재. 
- core : CPU 내부에 있는 단일 프로세싱 유닛. 레지스터, 일부 캐시 등을 포함.

소프트웨어 관점에서는 크게 다르지 않음. 아래의 논의에서는 둘을 크게 구분 짓지 않고 multiprocessor system이라 칭할 것임.

multiprocessor scheduling을 운영체제에서는 생각할 수 밖에 없음.

#### Multiprocessor 구조
여러 특징이 있지만 여기서는 간단하게 메인 메모리는 processor들이 공유하고 cache는 각 processor가 독립적으로 갖고 있다는 특징이 중요.

자세한 내용은 컴퓨터 구조론을 다시 공부.

#### Multiprocessor의 문제점 및 고려 사항
**cache coherence** : CPU1에서 메인 메모리 A 주소의 값을 cache로 가져와 이를 갱신했으면 메인 메모리에도 갱신을 해줘야하는데 cache와 메인 메모리 사이의 속도 차가 심하기 때문에 메인 메모리에는 나중에 갱신. 이 상황에서 CPU2가 A 주소의 값을 읽어오면 갱신된 값이 아니라 이전 값을 읽어오게 됨. bus snooping(메인 메모리와 cache 간 bus를 통한 통신상황을 각각의 cache가 계속 모니터링)을 사용할 수도 있지만 문제가 완전히 해결되는 것은 아님.

**mutual exclusion** : 여러 CPU가 데이터 아이템에 동시에 접근할 때도 올바른 연산 결과를 보장할 수 있어야 함. lock을 걸고 다른 CPU는 접근하지 못하게 막은 상황에서 데이터를 써야 함. 즉, 갱신은 반드시 원자적으로 이루어져야 됨. 성능 측면에서 문제가 있음(lock을 걸면 그 동안에 다른 cpu들은 일을 진행을 못 시키고 있기 때문에)

**cache affinity** : 실행될 때 프로세스는 CPU의 cache에 상당한 양의 정보를 올리게 되는데 다시 실행할 때마다 매번 다른 CPU면 해당 정보들을 다시 탑재해야 하므로 성능이 나빠짐.

#### Multiprocessor Scheduling
**SQMS(Single-Queue Multiprocessor Scheduling)** : 
- 의미 : 기존과 크게 다르지 않게 단일 queue에서 job을 뿌려줌.
- 장점 : 간단함
- 단점 :
    - 확장성의 결여 : 동시성 문제가 발생해서 lock을 써야하는데 lock이 성능을 저하시킴. 와닿지 않음. 그림이 안 그려짐. 운영체제가 각각의 CPU에서 모두 동작하고 있는거야? 하나의 CPU에서 동작하는거야? 뭐야
    - 캐시 친화성 문제 : 각 CPU는 단순히 공유 queue에서 다음 작업을 선택하기 때문에 프로세스는 CPU에서 CPU를 옮겨다니게 됨

**MQMS(Multi-Queue Multiprocessor Scheduling)** :
- 의미 : CPU당 하나의 queue. 각각의 queue는 특정한 scheduling discipline을 따르도록 설정. job이 들어오면 특정한 scheduling queue에서만 계속 실행. 
- 장점 : 위에서 언급한 2가지 문제를 해결해줌.
- 단점 : 
    - load imbalance : job이 프로세서 간에 균등하게 배분되지 않는 상태.

migration : 프로세스를 이주시켜야 하며, 여기에는 다양한 패턴이 존재. 대표적으로 work stealing이 존재하는데, job의 개수나 낮은 queue가 자신보다 많이 차 있는 다른 queue가 있는지 검사하고 찾았다면 하나 이상의 작업을 가져옴.
