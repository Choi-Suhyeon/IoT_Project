### 1. 스케줄링 : 비례 배분
- 반환 시간이나 응답 시간을 최적화하는 대신 스케줄러가 각 작업에게 CPU의 일정 비율을 보장하는 것이 목적
- 비례 배분 스케줄링의 좋은 예가 Waldspurger and Weihl의 연구의 연구로 **추첨 스케줄링(lottery scheduling)** 으로 알려져 있으며 이 아이디어는 꽤 오래됨
  - 다음 실행될 프로세스를 추첨을 통해 결정하며, 더 자주 수행되어야 하는 프로세스는 당첨 기회를 더 많이 줌 

<br>

#### 1.1. 추첨권이 당신의 몫을 나타낸다
- 추첨권(티켓)이라는 기본적인 개념이 추첨 스케줄링의 근간을 이루며, 추첨권은 프로세스가 받아야 할 자원의 몫을 나타내는 데 사용됨
- 프로세스가 소유한 티켓의 개수와 전체 티켓에 대한 비율이 자신의 몫을 나타냄

<br>

- 추첨 스케줄링은 이러한 목적을 (타임 슬라이스가 끝날 때마다) 확률적으로 (하지만 결정적이지는 않게) 달성함
- 무작위성은 원하는 비율을 정확히 보장하지는 않지만 작업이 장시간 실행될수록, 원하는 비율을 달성할 가능성이 높아짐


<br>

#### 1.2. 추첨 기법
- 추첨권을 다루는 다양한 기법 중 **추첨권 화폐(ticket currency)** 의 개념은 사용자가 추첨권을 자신의 화폐 가치로 추첨권을 자유롭게 할당할 수 있도록 허용함
- 시스템은 자동적으로 화폐 가치를 변환함
  ```
    User A −> 500 (A's currency) to A1 −> 50 (global currency)
           −> 500 (A's currency) to A2 −> 50 (global currency)
    User B −> 10 (B's currency) to B1 −> 100 (global currency)
  ```

<br>

- 다른 유용한 기법은 **추첨권 양도(ticket transfer)**
  - 양도를 통하여 프로세스는 일시적으로 추첨권을 다른 프로세스에게 넘겨줄 수 있음
  - 이 기능은 클라이언트/서버 환경에서 특히 유용
    - 클라이언트 프로세스는 서버에게 메시지를 보내 자신을 대신해 특정 작업을 해달라고 요청
    - 작업이 빨리 완료될 수 있도록 클라이언트는 서버에게 추첨권을 전달하고 서버가 자신의 요청을 수행하는 동안 서버의 성능을 극대화하려고 함
    - 요청을 완수하면 서버는 추첨권을 다시 클라이언트에게 되돌려 줌

<br>

- 마지막으로, **추첨권 팽창(ticket inlation)** 도 유용하게 사용됨
  - 이 기법에서 프로세스는 일시적으로 자신이 소유한 추첨권의 수를 늘이거나 줄일 수 있음
  - 화폐 팽창 기법은 프로세스들이 서로 신뢰할 때 유용하며, 그런 경우 어떤 프로세스가 더 많은 CPU 시간을 필요로 한다면 시스템에게 이를 알리는 방법으로 다른 프로세스들과 통신하지 않고 혼자 추첨권의 가치를 상향 조정함



<br>

#### 1.3. 구현
- 추첨 스케줄링의 가장 큰 장점은 구현이 단순하다는 점
- 필요한 것은 난수 발생기와 프로세스들의 집합을 표현하는 자료 구조(예, 리스트), 추첨권의 전체 개수 뿐

<br>

- 추첨 스케줄링 결정 코드
  ```
    // 리스트를 사용하여 프로세스를 관리한다고 가정
    //A, B, C 세 개의 프로세스로 구성되고 각자 몇 장의 추첨권을 가짐
    // counter : 당첨자를 발견했는지 추적하는데 사용됨
    int counter = 0;
    
    // winner : 0부터 총 추첨권의 수 사이의 임의의 값을 얻기 위해 난수 발생기를 호출함
    int winner = getrandom(0, totaltickets);
    
    // current : 작업 목록을 탐색하는데 사용
    node_t *current = head;
    
    // 티켓 값 > winner를 만족할 때까지 반복
    while (current) {
      counter = counter + current−>tickets;
      if (counter > winner)
        break;      // 당첨자 발견
      current = current−>next;
    }
    // "current"는 당첨자를 가리킴 : 당첨자가 실행될 수 있도록 준비
  ```
  - 일반적으로 리스트를 내림차순으로 정렬하면 이 과정이 가장 효율적이 되며 정렬 순서는 알고리즘의 정확성에 영향을 주지는 않음
  - 그러나 리스트를 정렬해 놓으면 검색 횟수가 최소화되는 것을 보장함
    - 특히, 적은 수의 프로세스가 대부분의 추첨권을 소유하고 있는 경우에 효과적


<br>

#### 1.4. 추첨권 배분 방식
- 추첨 스케줄링에서 아직 언급하지 않은 문제는 추첨권을 작업에게 나누어주는 방식
- 시스템 동작이 추첨권 할당 방식에 따라 크게 달라지기 때문에 상당히 어려운 문제
- 한 가지 접근 방식은 사용자가 가장 잘 알고 있다고 가정하는 것
  - 각 사용자에게 추첨권을 나누어 준 후 사용자가 알아서 실행시키고자 하는 작업들에게 추첨권을 배분하는 것
- 하지만 이건 해결책이 아니며 주어진 작업 집합에 대한 추첨권 할당 문제는 여전히 미해결 상태


<br>

#### 1.5. 왜 결정론적(Deterministic) 방법을 사용하지 않는가
- 무작위성을 이용하면 스케줄러를 단순하게(그러나 어느 정도 정확하게) 만들 수 있지만, 정확한 비율을 보장할 수 없으며 짧은 기간만 실행되는 경우는 더 그렇게 됨
- 이 때문에 Waldspurger는 결정론적 공정 배분 스케줄러인 **보폭 스케줄링(stride scheduling)** 을 고안하였음

<br>

- 보폭 스케줄링
  - 시스템의 각 작업은 보폭을 가지고 있으며, 보폭은 자신이 가지고 있는 추첨권 수에 반비례하는 값
  - 프로세스가 실행될때마다 pass라는 값을 보폭만큼 증가시켜 얼마나 CPU를 사용하였는지를 추적
  - 스케줄러는 보폭과 pass 값을 사용하여 어느 프로세스를 실행시킬지 결정함
  - 가장 작은 pass 값을 가진 프로세스를 선택하며, 프로세스를 실행시킬 때마다 pass 값을 보폭만큼씩 증가시킴
  - Waldspurger가 작성한 의사코드
    ```
      current = remove_min(queue);   // pass 값이 최소인 클라이언트로 선택
      schedule(current);     // 자원을 타임 퀀텀만큼 선택된 프로세스에게 할당
      current−>pass += current−>stride;     // ݅다음 pass 값을 보폭 값을 이용하여 갱신
      insert(queue, current);     // ݅다시 큐에 저
    ```

<br>

- 추첨 스케줄링은 정해진 비율에 따라 확률적으로 CPU를 배분하며, 보폭 스케줄링은 각 스케줄링 주기마다 정확한 비율로 CPU를 배분함
- 추첨 스케줄링에서는 새 프로세스를 쉽게 추가할 수 있지만, 보폭 스케줄링은 어려움
- 둘 다 개념적으로 흥미롭지만 여러 이유로 CPU 스케줄러로서 널리 사용되고 있지 않음
  - 이유는 이러한 접근 방식이 특히 입출력과 맞물렸을 때, 제대로 동작하지 않는다는 것
  - 또 다른 이유는 추첨권 할당이라는 어려운 문제가 미해결 상태로 남아있다는 것

<br>

- 비례 배분 스케줄러는 추첨권 할당량을 비교적 정확하게 결정할 수 있는 환경에서 유용하게 사용됨
- 예를 들어, 가상화 데이터 센터에서 Windows 가상 머신에 CPU 사이클의 1/4을 할당하고 나머지는 Linux 시스템에 할당하고 싶은 경우 비례 배분이 간단하고 효과적임



<br>
<br>

### 2. 멀티프로세서 스케줄링 (고급)
- 고사양 컴퓨터에만 존재했던 **멀티프로세서(multiprocessor)** 시스템은 일반적이 되었으며 데스크톱 컴퓨터, 노트북, 심지어 모바일 장치에도 사용되고 있음
- 여러 개의 CPU 코어가 하나의 칩에 내장된 **멀티코어(multicore)** 프로세서가 대중화의 근본 원인
- 싱글코어 CPU의 성능 개선이 한계에 봉착하면서 멀티코어 기술이 각광을 받게 됨
- 다중 CPU 시대가 오면서 많은 문제가 발생하였는데 가장 중요한 것은 전통적 응용 프로그램은(예, C 프로그램) 오직 하나의 CPU만 사용한다는 것
- 더 많은 CPU를 추가해도 더 빨리 실행되지 않음
- 이 문제를 해결하려면 응용 프로그램을 병렬(parallel)로 실행되도록 다시 작성해야 함


<br>

#### 2.1. 배경 : 멀티프로세서 구조
- 멀티프로세서 스케줄링에 대한 새로운 문제점을 이해하기 위해서는 단일 CPU 하드웨어와 멀티 CPU 하드웨어의 근본적인 차이에 대한 이해가 필요
  - 다수의 프로세서간에 데이터의 공유, 그리고 하드웨어 캐시의 사용 방식에서 근본적인 차이가 발생함

<br>

- 단일 CPU 시스템에는 하드웨어 캐시 계층이 존재하며 이 캐시는 프로그램을 빠르게
실행하기 위해 존재
- 캐시는 메인 메모리에서 자주 사용되는 데이터의 복사본을 저장하는 작고 빠른 메모리
- 메인 메모리는 모든 데이터를 저장하지만 느리며, 자주 접근되는 데이터를 캐시에 임시로 가져다 둠으로써 시스템은 크고 느린 메모리를 빠른 메모리처럼 보이게 함

<br>

- 캐시는 **지역성(locality)** 에 기반하며, 지역성에는 **시간 지역성(temporal locality)** 과 **공간 지역성(spatial locality)** 의 두 종류가 있음
- 시간적 지역성의 기본 아이디어는 데이터가 한 번 접근되면 가까운 미래에 다시 접근되기 쉽다는 것
- 공간적 지역성의 기본 아이디어는 프로그램이 주소 x의 데이터를 접근하면 x 주변의 데이터가 접근되기 쉽다는 것

<br>

- 멀티프로세서 시스템에서 발생 할 수 있는 문제
  - **캐시 일관성 문제(cache coherence)**
    - 기본적인 해결책은 하드웨어에 의해 제공됨
    - 하드웨어는 메모리 주소를 계속 감시하고 항상 제대로된 상황만 발생토록 시스템을 관리
    - 특히, 여러 개의 프로세스들이 하나의 메모리에 갱신할 때에는 항상 공유되도록 함
  - 버스 기반 시스템에서는 **버스 스누핑(bus snooping)** 이라는 오래된 기법을 사용
    - 캐시는 자신과 메모리를 연결하는 버스의 통신 상황을 계속 모니터링
    - 캐시 데이터에 대한 변경이 발생하면, 자신의 복사본을 무효화(invalidate) 시키거나(즉, 자신의 캐시에서 삭제) 갱신(새로운 값을 캐시에 기록) 함
  - 나중 쓰기 (write-back) 캐시는 메인 메모리에 쓰기 연산이 지연되기 때문에 캐시 일관성 유지 문제를 훨씬 복잡하게 만듬



<br>

#### 2.2. 동기화를 잊지 마시오
- CPU들이 동일한 데이터 또는 구조체에 접근할 때(특히, 갱신), 올바른 연산 결과를 보장하기 위해 락과 같은 상호 배제를 보장하는 동기화 기법이 많이 사용됨
- **락프리(lock-free)** 데이터 구조 등의 다른 방식은 복잡할 뿐 아니라 특별한 경우에만 사용됨
- 구조체를 원자적으로 갱신하기 위해서는 락이 필요함
- CPU의 개수가 증가할수록 동기화된 자료 구조에 접근하는 연산은 매우 느리게 됨

<br>

- 간단한 리스트의 삭제 코드
  ```
    typedef struct _ _Node_t {
      int value;
      struct _ _Node_t *next;
    } Node_t;
    
    int List_Pop() {
      Node_t *tmp = head;       // 이전 head를 기억..
      int value = head−>value;  // .. 값도 기억
      head = head−>next;        // head를 다음 포인터로 이동
      free(tmp);                // 이전 head 해제
      return value;             // head의 값을 반환
    }
  ```


<br>

#### 2.3. 마지막 문제점 : 캐시 친화성
- 멀티프로세서 캐시 스케줄러에서의 마지막 문제점은 **캐시 친화성(cache ainity)**
- CPU에서 실행될 때 프로세스는 해당 CPU 캐시와 TLB에 상당한 양의 상태 정보를 올려 놓게 됨
- 다음 번에 프로세스가 실행될 때 동일한 CPU에서 실행되는 것이 유리하며, 해당 CPU 캐시에 일부 정보가 이미 존재하고 있기 때문에 더 빨리 실행될 것이기 때문임
- 반면 프로세스가 매번 다른 CPU에서 실행되면 실행할때마다 필요한 정보를 캐시에 다시 탑재해야만 하기 때문에 프로세스의 성능은 더 나빠질 것
- 하드웨어의 캐시 일관성 프로토콜 덕분에 다른 CPU에서 실행되더라도 프로그램이 제대로 실행될 것임
- 멀티프로세서 스케줄러는 스케줄링 결정을 내릴 때 캐시 친화성을 고려해야 하며, 가능한 한 프로세스를 동일한 CPU에서 실행하려고 노력하는 방향으로 결정해야 함



<br>

#### 2.4. 단일 큐 스케줄링
- 멀티프로세서 시스템의 스케줄러를 개발할 때 가장 기본적인 방식은 단일 프로세서 스케줄링의 기본 프레임워크를 그대로 사용 하는 것
- 이러한 방식을 **단일 큐 멀티프로세서 스케줄링(single queue multiprocessor scheduling, SQMS)** 이라고 부름
- 이 방식의 장점은 단순함이며, 기존 정책을 다수 CPU에서 동작하도록 하는 데는 많은 변경이 필요치 않음

<br>

- 단점
  - 첫 번째 문제는 **확장성(scalability)** 결여
    - 스케줄러가 다수의 CPU에서 제대로 동작하게 하기 위해 코드에 일정 형태의 락을 삽입함
    - 락은 SQMS 코드가 단일 큐를 접근할 때(즉, 실행시킬 다음 작업을 찾을 때) 올바른 결과가 나오도록 함
    - 락은 성능을 크게 저하시킬 수 있고, 시스템의 CPU 개수가 증가할수록 더욱 그렇게 됨
    - 단일 락에 대한 경쟁이 증가할수록 시스템은 락에 점점 더 많은 시간을 소모하게 되고 실제 필요한 일에 쓰는 시간은 줄어들게 됨
  - 두 번째 주요 문제는 캐시 친화성
    - 각 CPU는 공유 큐에서 다음 작업을 선택하기 때문에 각 작업은 CPU를 옮겨 다니게되며 캐시 친화성 관점에서 보면 잘못된 선택을 하는 것
    - 이 문제의 해결을 위해 대부분의 SQMS 스케줄러는 가능한 한 프로세스가 동일한 CPU에서 재실행될 수 있도록 시도함
    - 구체적으로, 특정 작업들에 대해서 캐시 친화성을 고려하여 스케줄링하고 다른 작업들은 오버헤드를 균등하게 하기 위해 여러 군데로 분산시키는 정책을 사용



<br>

#### 2.5. 멀티 큐 스케줄링
- 단일 큐 스케줄러로 인한 문제 때문에 일부 시스템은 멀티 큐, 예를 들어, CPU마다 큐를 하나씩 둠
- 이 방식을 **멀티 큐 멀티프로세서 스케줄링(multi-queue multiprocessor scheduling, MQMS)** 이라고 부름
- MQMS에서 기본적인 스케줄링 프레임워크는 여러 개의 스케줄링 큐로 구성됨
- 각 큐는 아마도 라운드 로빈 같은 특정 스케줄링 규칙을 따를 것이고 물론 어떤 스케줄링 기법도 사용 가능
- 작업이 시스템에 들어가면 하나의 스케줄링 큐에 배치되며, 배치될 큐의 결정은 적당한 방법을 따름
  - 예를 들어, 무작위로 할 수도 있고 또는 다른 큐보다 작은 수의 작업이 있는 큐로 배치할 수도 있음
- 그 후에는 각각 독립적으로 스케줄 되기 때문에 단일 큐 방식에서 보았던 정보의 공유 및 동기화 문제를 피할 수 있음
- MQMS가 SQMS에 비해 가지는 명확한 이점은 확장성이 좋다는 것
- CPU 개수가 증가할수록, 큐의 개수도 증가하므로 락과 캐시 경합(cache contention)은 더 이상 문제가 되지 않으며, MQMS는 본질적으로 캐시 친화적임
 - 작업이 같은 CPU에서 계속 실행되기 때문에 캐시에 저장된 내용을 재사용하는 이점을 얻게 됨

<br>

- 멀티 큐 기반 방식의 근본적인 문제는 **워크로드의 불균형(load imbalance)**
- 해결 방법은 작업을 이리저리로 이동시키는 것
- 이 기술을 **이주(migration)** 라고 부름
- 작업을 한 CPU에서 다른 CPU로 이주시킴으로써 워크로드 균형을 이룸
- **작업 훔치기(work stealing)**
  - 작업 훔치기에서는 작업의 개수가 낮은 (소스) 큐가 가끔 다른 (대상) 큐에 훨씬 많은 수의 작업이 있는지를 검사함
  - 대상 큐가 소스 큐보다 더 가득 차 있다면 워크로드 균형을 맞추기 위해 소스는 대상에서 하나 이상의 작업을 가져옴
  - 여기서 문제는 큐를 너무 자주 검사하게 되면 높은 오버헤드로 확장성에 문제가 생기게 됨




<br>

#### 2.6. Linux 멀티프로세서 스케줄러
- Linux 커뮤니티에서는 멀티프로세서 스케줄러를 위한 단일화된 방식이 존재하지 않았음
- 세 가지 스케줄러가 등장하였는데 O(1) 스케줄러, Completely Fair Scheduler(CFS) 및 BF
스케줄러(BFS)
- O(1)과 CFS는 멀티 큐를, BFS는 단일 큐를 사용하기 때문에 두 방식 모두 실제 시스템에서 성공적으로 사용할 수 있음
- 물론, 이 스케줄러를 구분하는 다른 많은 분류 기준들이 존재
  - O(1) 스케줄러는 우선순위 기반 스케줄러로서(MLFQ와 유사) 프로세스의 우선순위를 시간에 따라 변경하여 우선순위가 가장 높은 작업을 선택하여 다양한 목적을 만족시키며 특히, 상호작용을 가장 우선시 함
  - 반면에 CFS는 결정론적(deteministic) 비례배분(proportional share) 방식(보폭 스케줄링에 가까움)
  - BFS는 셋 중에서 유일한 단일 큐 방식이며 또한 비례배분 방식
    - 그러나 Earliest Eligible Virtual Deadline First(EEVDF)라고 알려진 더 복잡한 방식에 기반을 둠


















