## 클럭

4장에서 컴퓨터 부품들은 **클럭 신호**에 맟춰 일사불란하게 움직인 뒤 CPU는 **명령어 사이클**이라는 정해진 흐름에 맞춰 명령어들을 실행한다는 내용을 학습했다.

- 클럭 속도가 높아질 경우 CPU를 비롯한 컴퓨터 부품들은 명령어 사이클을 더 빠르게 작동시킬 수 있다.
    - 실제로 클럭 속도가 높은 CPU는 일반적으로 성능이 좋다.
    - 그래서 클럭 속도는 CPU 속도 단위로 간주된다.
    - 단, 클럭 속도가 빠르다고 무조건 CPU가 빨라지는 것은 아니다. (발열의 문제 등이 있음.)
- **클럭 속도**는 헤르츠(HZ) 단위로 측정을 한다. 이는 1초에 클럭이 몇번 반복되는지를 나타내다.
    - 가령 클럭이 1초에 한번 반복되면 CPU 클럭의 속도는 1HZ인 것이고, 클럭이 1초에 100번 반복되면 CPU 클럭 속도는 100 HZ가 된다.
    - 실제의 클럭 속도는 I7-1170 CPU를 기반으로 했을 때 기본 속도는 2.5GHZ, 최대 속도는 4.9CHZ라는 것을 알 수 있다. 이는 기본이 25억번, 순간이 49억번 반복된다.
- **클럭의 속도는 일정치 않는데**, CPU는 계속 일정한 속도를 유지하기보다는 고성능을 요하는 순간에는 속도를 올리고 낮추기도 한다.
    - 최대 클럭 속도를 강제로 더 끌어올릴 수도 있는데, 이런 기법을 **오버클럭킹(overclocking)**이라고 한다.

## 코어와 멀티코어

클럭 속도를 제외하고 CPU의 성능을 높이는 방법에는 CPU의 코어와 스레드를 늘리는 방법이 있다. 우선 우리는 코어를 늘리는 방법을 알려고 한다.

### 코어

코어를 이해하기 위해 CPU를 먼저 알아야 한다. 앞서 **CPU는 “명령어를 실행하는 부품”**이라고 하였다. 원칙적으로 명령어를 실행하는 부품은 하나만 존재했으나, 많은 기술적 발전으로 인해 **CPU 내부에서도 “명령어를 실행하는 부품”을 얼마든지 만들 수 있게 되었다.**

우리가 지금까지 알고 있던 CPU의 정의인 “명령어를 실행하는 부품”은 오늘날 **“코어”**라는 용어로 사용이 된다. 

- 오늘 날의 CPU는 **“명령어를 실행하는 부품을 여러 개 포함하는 부품”**으로 명칭의 범위가 확장되었다.
    - 앞서 본 I7 CPU의 경우, 8코어라고 적혀있었는데 이는 “명령어를 실행하는 부품”을 8개 포함하고 있다고 보면 된다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/970ff13a-5200-405b-aefb-11bbe7b980e7/ae419ae5-518a-46c5-8d62-00803bddb769/Untitled.png)

- 우리는 코어를 여러 개 포함하고 있는 CPU를 **멀티코어(multi-core)** 또는 **멀티코어 프로세서**라고 부른다.
    - 멀티 코어의 처리 속도가 단일 코어보다 훨씬 빠르다.
    - 가령 클럭 속도가 2.4GHZ인 단일 코어 CPU와 클럭 속도가 1.9GHZ인 멀티코어 CPU를 비교하면 후자의 성능이 좋다.
- CPU의 종류는 CPU 안에 코어가 몇 개 포함되어 있는데 따라 싱글 코어, 듀얼 코어, 트리플 코어 등으로 나뉜다.
- 또한, **CPU의 연산속도가 코어 수에 비례하여 증가하지는 않는다.**
- **중요한 것은 코어마다 처리할 연산을 적절히 분배하는 것이다.**

### 스레드와 멀티스레드

- 스레드에는 CPU에 사용이 되는 **하드웨어적 스레드**가 있고, 프로그램에서 사용이 되는 **소프트웨어적 스레드**가 있다.

**********************하드웨어적 스레드**********************

- 스레드를 하드웨어적으로 정의하면 **‘하나의 코어가 동시에 처리하는 명령어 단위’**를 의미한다.
- 여러 스레드를 지원하는 CPU는 하나의 코어로도 여러 개의 명령어를 동시에 실행할 수 있다.
    - 예를 들어 2코어 4스레드 CPU는 명령어를 실행하는 부품을 두 개 포함하고, 한 번에 네 개의 명령어를 처리할 수 있는 CPU를 의미한다.
- 이처럼 하나의 코어로 여러 명령어를 동시에 처리하는 CPU를 **멀티스레드 프로세서** 또는 **멀티스레드 CPU**라고 한다.
    - 참고로 하이퍼스레딩(hyper-htreding)이라는 용어가 있는데, 이는 인텔의 멀티스레드 기술을 의미한다.

**************************************************소프트웨어적 스레드**************************************************

- 소레드를 소프트웨어적으로 정의하면 **‘하나의 프로그램에서 독립적으로 실행하는 단위’**를 의미한다.
- 우리가 보통 프로그래밍 언어나 운영체제를 학슬할 때 접하는 스레드는 보통 이렇게 소프트웨어적으로 정의된 스레드를 의미한다.
- 하나의 프로그램은 실행되는 과정에서 한 부분만 실행될 수도 있지만, 프로그램의 여러 부분이 동시에 실행될 수도 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/970ff13a-5200-405b-aefb-11bbe7b980e7/a7ca54ce-c179-4e97-b129-57736210b41d/Untitled.png)

실행부가 스레드라고 보면된다.

가령 우리가 워드 프로세서 프로그램을 개발한다 치자.

1. 사용자로부터 입력받은 내용을 화면에 보여 주는 기능
2. 사용자가 입력한 내용이 맞춤법에 맞는지 검사하는 기능
3. 사용자가 입력한 내용을 수시로 저장하는 기능

→ 이 기능들을 작동시키는 코드를 각각의 스레드로 만들면 동시에 실행할 수 있다. 

### 멀티스레드 프로세서

- 멀티스레드 프로세서는 하나의 코어로 여러 명령어를 동시에 처리하는 CPU이다.
- 멀티스레드 프로세서를 실제로 설계하는 일은 매우 복잡하지만, 가장 큰 핵심은 **레지스터**이다.
    - 하나의 코어로 여러 명령어를 동시에 처리할 수 있게 하려면 **프로그램 카운터, 스택 포인터, 메모리 버퍼 레지스터, 메모리 주소 레지스터와 같이 하나의 명령어를 처리하기 위해 꼭 필요한 레지스터**를 여러 개 가지고 있으면 된다.
    - 예시로, 프로그램 카운터가 두 개 있다면 메모리에서 가져올 명령어 주소를 두 개 지정할 수 있을 것이고, 스택 포인터가 두 개 있다면 두 개의 스택을 관리할 수 있다.
- 하나의 명령어를 실행하기 위해 꼭 필요한 레지스터들을 편의상 ‘레지스터 세트’라고 표기했다.
    - 레지스터 세트가 한 개인 CPU는 한 개의 명령어를 처리하기 위한 정보들을 기억하지만, 두 개의 세트를 지닌 경우는 두 개의 명령어를 위한 정보들을 기억한다.
    - **ALU와 제어장치**가 두 개의 레지스터 세트에 저장된 명령어를 해석하고 실행하면 하나의 코어에서 두 개의 명령어가 동시에 실행된다.
- 하드웨어 스레드를 이용해 하나의 코어로도 여러 명령어를 실행할 수 있으나, 메모리 속 프로그램 입장에서 봤을 때 하드웨어 스레드는 마치 ‘한 번에 하나의 명령어를 처리하는 CPU’나 다름이 없다.
- 그래서 하드웨어 스레드를 **논리 프로세서**라고도 부른다.

정리하자면, **코어**는 명령어를 실행할 수 있는 **‘하드웨어 부품’**이고 **스레드**는 **‘명령어를 실행하는 단위’**이다. **멀티코어 프로세서**는 명령어를 실행할 수 있는 하드웨어 부품이 CPU 안에 두 개 이상 있는 CPU를 의미하며 **멀티스레드 프로세서**는 하나의 코어로 여러 개의 명령어를 동시에 실행할 수 있는 CPU를 의미한다.

# 명령어 병렬 처리 기법

빠른 CPU를 만들려면 높은 클럭 속도에 멀티코어, 멀티스레드를 지원하는 CPU를 마드는 것도 중요하지만, CPU가 놀지 않고 시간을 알뜰하게 쓰는 것도 중요하다.

명령어를 동시에 처리하여 CPU를 쉬지 않고 작동시키는 기법인 **명령어 병렬 처리 기법**에는 **명령어 파이프 라이닝, 슈퍼 스칼라, 비순차적 명령어 처리**가 있다.

## 명령어 파이프 라인

명령어 처리 과정을 클럭 단위로 나누어 보면 밑과 같다.

1. 명령어 인출(Instruction Fetch)
2. 명령어 해석(Instruction Decode)
3. 명령어 실행(Execute Instruction)
4. 결과 저장(Write Back)

→여기서 중요한 점은 같은 단계가 겹치지만 않는다면 CPU는 ‘각 단계를 동시에 실행할 수 있다’는 것이다. 

예를 들어, CPU는 한 명령어를 ‘인출’하는 동안에 다른 명령어를 ‘실행’할 수 있고, 한 명령어가 ‘실행’되는 동안에 연산 결과를 ‘저장’할 수 있다. 밑의 사진을 보면 이해가 쉬울 것이다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/970ff13a-5200-405b-aefb-11bbe7b980e7/1198e8ad-4894-4e18-928b-f6541a7d6865/Untitled.png)

이처럼 명령어들을 명령어 파이프라인에 넣고 동시에 처리하는 기법을 **명령어 파이프라이닝(Instruction pipelining)**이라고 한다.

파이프 라이닝이 높은 성능을 가져오지만, 특정 상황에서 성능 향상에 실패할 수 있다. 우리는 이러한 상황을 **파이프라인 위험**이라고 부른다. 파이프라인 위험에는 크게 **데이터 위험, 제어 위험, 구조적 위험**이 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/970ff13a-5200-405b-aefb-11bbe7b980e7/d9741b85-4e00-4085-9c87-15b8f37f8804/Untitled.png)

**데이터 위험**

- 데이터 위험은 명령어 간 **‘데이터 의존성’**에 의해 발생한다.
- 모든 명령어를 동시에 처리할 수 없다. 어떤 명령어는 이전 명령어를 끝까지 실행해야만 비로소 실행할 수 있는 경우가 있다.

```jsx
명령어1: R1 <- R2+ R3//R2 레지스터 값과 R3 레지스터 값을 더한 값을 R1 레지스터에 저장
명령어2: R4 <- R1 + R5 //R1 레지스터 값과 R5 레지스터 값을 더한 값을 R4 레지스테 저장
```

위의 경우 명령어 1을 수행해야만 명령어 2를 수행할 수 있다. 만약 명령어 1이 끝나기 전에 명령어 2를 인출할 경우 적절한 값이 나오지 않을 것이다. **따라서 명령어 2는 명령어 1의 데이터에 의존적이다.** 

이처럼 데이터 의존적인 두 명령어를 동시에 실행하려 할 경우 파이프라인이 제대로 작동하지 않는 것을 ‘데이터 위험’이라고 한다.

********************제어 위험********************

- 제어 위험은 주로 분기 등으로 인한 ‘프로그램 카운터의 갑작스러운 변화’에 의해 발생한다.
- 기본적으로 프로그램 카운터는 ‘현재 실행 중인 명령어의 다음 주소’로 갱신된다.
- 하지만 프로그램 실행 흐름이 바뀌어 명령어가 실행되면서 프로그램 카운터 값에 갑작스러운 변화가 생긴다면 명령어 파이프라인에 미리 가지고 와 처리 중이던 명령어들은 아무 쓸모가 없어짐.
- 이러한 것들을 방지하기 위해 **분기 예측**이라는 기술을 사용한다. 분기 예측은 프로그램이 어디로 분기할지 미리 예측 후 그 주소를 인출하는 것이다.

**구조적 위험**

- 명령어들을 겹쳐 실행하는 과정에서 서로 다른 명령어가 동시에 ALU, 레지스터 등과 같은 CPU 부품을 사용하려고 할 때 발생한다.
- 구조적 위험은 **************************자원 위험**************************이라고 부른다.

## 슈퍼스칼라

- CPU 내부에 여러 개의 명령어 파이프라인을 포함한 구조를 **슈퍼 스칼라**라고 한다.
- 명령어 파이프라인을 하나만 두는 것이 마치 공장 생산 라인을 한 개 두는 것과 같다면, 슈퍼스칼라는 공장 생산 라인을 여러 개 두는 것과 같다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/970ff13a-5200-405b-aefb-11bbe7b980e7/e46ffed0-439f-4281-a587-09ea40d038dc/Untitled.png)

- 슈퍼스칼라 구조로 명령어 처리가 가능한 CPU를 **슈퍼스칼라 프로세서** 또는 **슈퍼스칼라 CPU**라고 한다.
- 슈퍼스칼라 프로세서는 매 클럭 주기마다 동시에 여러 명령어를 인출할 수도, 실행할 수도 있어야 한다.
    - 가령 멀티스레드 프로세서는 한 번에 여러 명령어를 인출하고, 해석하고, 실행할 수 있기 때문에 슈퍼 스칼라 구조를 사용할 수 있다.
- 슈퍼스칼라 프로세서는 이론적으로 파이프라인 개수에 비례하여 프로그램 처리 속도가 빨라진다.
    - 그러나 파이프라인 위험 등의 문제가 있어서 실제로는 반드시 파이프라인 개수에 비례하여 빨라지지는 않는다.
    - 파이프라인 위험을 방지하기 위해 고도로 섬세하게 설계되어야 함.

## 비순차적 명령어 처리

- 명령어들을 순차적으로 실행하지 않는 기법임.
- 보통 OoOE(out of order execution)으로 줄여 부른다.
- 오늘날 CPU 성능 향상에 크게 기여한 기법이자 대부분의 CPU가 차용한 방법.

이전에 설명했던 파이프라이닝, 슈퍼스칼라 기법은 모두 여러 명령어의 순차적인 처리를 상정한 방법임. 프로그램을 위에서 아래로 실행하는 방식이었음.

하지만 파이프라인 위험과 같은 예상치 못한 문제들로 인해 이따금씩 명령어는 곧바로 처리되지 못함. 만약 모든 명령어를 순차적으로만 처리한다면 이러한 상황에서 파이프라인은 멈춰 버림.

<aside>
💡 예를 들어, 먼저 들어온 명령어 A는 실행시킬 수 없는 상태이지만, 뒤늦게 들어온 명령어 B는 바로 실행시킬 수 있는 경우에, 비순차적 명령어 처리 기법을 사용하면 명령어 B를 먼저 실행시키고, 그 후에 명령어 A를 실행시킵니다. 이렇게 함으로써 CPU의 대기 시간을 줄이고, 전체적인 성능을 향상시킬 수 있습니다.

</aside>

# CISC와 RISC

- 명령어 파이프라이닝과 슈퍼스칼라 기법을 실제로 CPU에 적용하려면 CPU가 인출하고 해석하고 실행하는 명령어가 파이프라이닝에 최적화되어 있어야 한다.
- CPU의 언어인 ISA와 각기 다른 성격의 ISA를 기반으로 설계된 CISC와 RISC를 설명.

## 명령어 집합

- 각 회사에서 만드는 CPU마다 조금씩 차이가 있으므로 명령어도 조금씩 차이가 있다.
- CPU가 이해할 수 있는 명령어들의 모음을 **명령어 집합** 또는 **명령어 집합 구조, ISA**라고 한다. 즉, CPU마다 ISA가 다를 수 있다.
    - 가령 인텔 노트북의 CPU는 x86 혹은 x87-64 ISA를 이해하고, 애플의 아이폰 속 CPU는 ARM ISA를 이해한다. 서로 다른 ISA이기 때문에 인텔과 아이폰은 서로 이해할 수 없다.
    - 서로 다른 ISA이기 때문에 같은 코드를 어셈블리할 경우 다른 결과를 얻는다.
    - 밑은 비교한 사진이다.
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/970ff13a-5200-405b-aefb-11bbe7b980e7/ac6a2cd2-2044-4ebd-90fd-fb68b1fd4818/Untitled.png)
    

→ 해당 사진을 보면, 똑같은 코드로 만든 프로그램이어도 CPU가 이해하고 실행할 수 있는 명령어가 달라 어셈블리어도 다른 것을 알 수 있다. 

- ISA가 다르면 그에 따른 제어장치가 명령어를 해석하는 방식, 사용되는 레지스터의 종류와 개수, 메모리 관리 방법 등 많은 것이 달라진다. → 이는 곧 CPU 하드웨어 설계에도 큰 영향을 미침.
- ISA는 CPU의 언어임과 동시에 CPU를 비롯한 하드웨어가 소프트웨어를 이해할 지에 대한 약속임.
- 각 파이프라인 방식에 따라 유리한 명령어 집합이 있고, 그렇지 못한 곳도 있다.

## CISC

- 이를 해석하면 **‘복잡한 명령어 집합을 활용하는 컴퓨터(=CPU)’**를 의미한다. CISC란 이름 그대로 복잡하고 다양한 명령어들을 활용하는 CPU 설계 방식임.
- x86, x86-64는 대표적인 CISC 기반의 ISA이다.
- CISC는 다양하고 강력한 기능의 명령어 집합을 활용하기 때문에 명령어의 형태와 크기가 다양한 **가변 길이 명령어**를 활용.
- 메모리에 접근하는 주소 지정 방식도 다양해서 아주 특별한 상황에서만 사용되는 독특한 주소 지정 방식도 있음.

**CISC**는 복잡한 명령어 세트 컴퓨터를 의미하며, 다양하고 복잡한 명령어와 주소 지정 모드를 사용합니다. CISC는 명령어의 길이가 가변적이며, 하나의 명령어가 수행할 수 있는 작업의 양이 많습니다. 이로 인해 파이프라인 설계가 어려울 수 있지만, 하나의 프로세서가 일련의 명령어를 순차적으로 처리하기에 유용합니다. 인텔의 x86 계열, AMD의 인텔 호환 CPU 등이 CISC 방식을 사용합니다.

반면에, **RISC**는 간소화된 명령어 세트 컴퓨터를 의미하며, 간단하고 적은 종류의 명령어와 주소 지정 모드를 사용합니다. RISC는 고정된 길이의 명령어를 사용하며, 명령어의 종류가 미리 정해져 있기 때문에 해석 속도가 빠르고 여러 개의 명령어를 처리하기에 적합합니다. 그러나, 처리 비트 단위가 변하거나 CPU의 구조가 조금만 바뀌면 하위 프로세서와의 호환성이 떨어질 수 있습니다. 애플의 PowerPC, IBM의 System/6000 기종 등이 RISC 방식을 사용합니다.

## CISC 장단점

**장점**

- 위의 컴파일 사진을 보면 알다시피 X86-64코드 길이가 ARM보다 짧은 것을 볼 수 있는데, 이는 CISC와 같이 다양하고 강력한 명령어를 활용한다는 말은 상대적으로 적은 수의 명령어로도 프로그램을 실행할 수 있다는 것을 의미함.
- 이러한 장점 덕에 적은 수의 명령어만으로 프로그램을 동작시킬 수 있었고, 메모리 공간을 절약할 수 있다.

**단점**

- 단점으로는 활용하는 명령어가 워낙 복잡하고 다양한 기능을 제공하여 명령어의 크기와 실행 시간이 일정하지 않다.
- 또한, 복잡한 명령어 때문에 명령어 하나를 실행하는 데에 여러 클럭 주기를 필요로 한다.
- 이로 인해서 파이프라인이 효율적으로 명령어를 처리할 수 가 없다. 이는 CISC 기반의 CPU의 효율에 좋지 않다.
- CISC가 복잡하고 다양한 명령어를 활용할 수 있다고는 하지만, 대다수의 복잡한 명령어는 그 사용 빈도가 낮다.

## RISC

- CISC의 한계를 보완하기 위해 등장한 것이 RISC이다.
- CISC의 한계로 인해 RISC를 개발하기 위한 목표치다.

<aside>
💡 1. 빠른 처리를 위해 명령어 파이프라인을 십분 활용해야 한다. 원할한 파이프라이닝을 위해 ‘명령어 길이와 수행 시간이 짧고 규격화’가 되어야 한다.
2. 어차피 자주 쓰이는 명령어만 줄곧 사용된다. 복잡한 기능을 지원하는 명령어를 추가하기보다는 ‘자주 쓰이는 기본적인 명령어를 작고 빠르게 만드는 것’이 중요함.

</aside>

- 이름처럼 RISC는 CISC에 비해 명령어 종류가 적다.
- CISC와는 달리 짧고 규격화된 명령어, 되도록 1클럭 내외로 실행되는 명령어를 지향함.
- RISC는 **고정 길이 명령어**를 활용한다.
- 명령어가 규격화되어 있고, 하나의 명령어가 1클럭 내외로 실행되기 때문에 RISC 명령어 집합은 명령어 파이프라이닝에 최적화되어 있다.
    - RISC는 메모리에 직접 접근하는 명령어를 load, store 두 개로 제한할 만큼 메모리 접근을 단순화하고 최소화를 추구.
    - 이런 점에서 RISC를 load-store 구조라고 부르기도 한다.
- RISC는 메모리 접근을 단순화, 최소화하는 대신 레지스터를 적극적으로 활용함.
    - CISC보다 레지스터를 이용하는 연산이 많고, 범용 레지스터의 개수도 적다.
- ARM이 RISC 기반의 대표적인 ISA이다.
