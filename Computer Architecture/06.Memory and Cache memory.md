# Chapter06 메모리와 캐시 메모리
<br>

## 06-1 RAM의 특징과 종류
### RAM의 특징
- RAM에는 실행할 프로그램의 명령어와 데이터가 저장
- 전원을 끄면 RAM에 저장된 명령어와 데이터가 모두 날아감
  -> 전원을 끄면 저장된 내용이 사라지는 **휘발성 저장 장치** 
  - 전원이 꺼져도 저장된 내용이 유지되는 저장 장치는 **비휘발성 저장 장치**
    - 하드 디스크나 SSD, CD-ROM, USB 메모리
- 보조기억장치는 전원을 꺼도 내용을 유지하지만, CPU는 보조기억장치에 직접 접근하지 못함
- 일반적으로 보조기억장치인 비휘발성 저장 장치에는 ‘보관할 대상’을 저장, 휘발성 저장 장치인 RAM에는 ‘실행할 대상’을 저장
- CPU가 실행하고 싶은 프로그램이 보조기억장치에 있다면 이를 RAM으로 복사하여 저장한 뒤 실행

<br>

### RAM의 용량과 성능
- CPU가 실행하고 싶은 프로그램이 보조기억장치에 있다면 이를 RAM으로 가져와야 하는데 RAM 용량이 적다면 보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어짐
- RAM 용량이 커지면 프로그램 실행 속도가 어느 정도 증가 하지만 용량이 필요 이상으로 커졌을 때 속도가 그에 비례하여 증가하지는 않음

<br>

### RAM의 종류
1. DRAM
    - Dynamic RAM의 준말
      - Dynamic은 영어로 ‘동적의’를 의미하는데, 이는 저장된 데이터가 동적으로 변하는(사라지는) RAM을 의미
    - 즉, DRAM은 시간이 지나면 저장된 데이터가 점차 사라지는 RAM
    - 데이터의 소멸을 막기 위해 일정 주기로 데이터를 재활성화(다시 저장)해야 함
    - 우리가 일반적으로 메모리로써 사용하는 RAM은 DRAM
      -> 소비 전력이 비교적 낮고, 저렴하고, 집적도가 높기 때문에 대용량으로 설계하기가 용이
2. SRAM
    - Static RAM의 준말
      - Static은 영어로 ‘정적의’를 의미하는데, 이는 저장된 데이터가 변하지 않는 RAM을 의미
    - 시간이 지나도 저장된 데이터가 사라지지 않으며 주기적으로 데이터를 재활성화할 필요가 없음
    - SRAM은 DRAM보다 일반적으로 속도도 더 빠름
    - 전원이 공급되지 않으면 저장된 내용이 날아감
    - DRAM보다 집적도가 낮고, 소비 전력도 크며, 가격도 더 비쌈
    - 그래서 메모리가 아닌 ‘대용량으로 만들어질 필요는 없지만 속도가 빨라야 하는 저장 장치’(캐시 메모리)에서 사용됨
3. SDRAM
    - 클럭 신호와 동기화된, 발전된 형태의 DRAM
    - ‘클럭 신호와 동기화되었다’는 말은 클럭 타이밍에 맞춰 CPU와 정보를 주고받을 수 있음을 의미
      - 즉, SDRAM은 클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고받을 수 있는 DRAM
4. DDR SDRAM
    - 최근 가장 흔히 사용되는 RAM
    - 대역폭을 넓혀 속도를 빠르게 만든 SDRAM
      - 대역폭이란 ‘데이터를 주고받는 길의 너비’를 의미
    - 한 클럭에 한 번씩 CPU와 데이터를 주고받을 수 있는 SDRAM에 비해 DDR SDRAM은 두 배의 대역폭으로 한 클럭당 두 번씩 CPU와 데이터를 주고받을 수 있음
    - DDR SDRAM의 전송 속도가 두 배가량 빠름
    - 이런 이유에서 한 클럭당 하나씩 데이터를 주고받을 수 있는 SDRAM을 SDR SDRAM이라 부르기도 함
    - DDR2 SDRAM은 DDR SDRAM보다 대역폭이 두 배 넓음
    - DDR3 SDRAM은 DDR2 SDRAM보다 대역폭이 두 배 넓고, SDR SDRAM보다 대역폭이 여덟 배 넓은 SDRAM
    - 최근에 흔히 사용하는 메모리는 DDR4 SDRAM으로, SDR SDRAM보다 열여섯 배 넓은 대역폭을 가짐


<br><br><br>

## 06-2 메모리의 주소 공간
- **물리 주소**는 메모리 하드웨어가 사용하는 주소, **논리 주소**는 CPU와 실행 중인 프로그램이 사용하는 주소

<br>

### 물리 주소와 논리 주소
- CPU와 메모리에 저장되어 실행 중인 프로그램은 메모리 몇 번지에 무엇이 저장되어 있는지 다 알지 못함
  - 그 이유는 메모리에 저장된 정보는 시시각각 변하기 때문
- 메모리가 사용하는 **물리 주소**는 말 그대로 정보가 실제로 저장된 하드웨어상의 주소를 의미
- CPU와 실행 중인 프로그램이 사용하는 **논리 주소**는 실행 중인 프로그램 각각에게 부여된 0번지부터 시작되는 주소를 의미
- 메모리가 사용하는 주소는 하드웨어상의 실제 주소인 물리 주소이고, CPU와 실행 중인 프로 그램이 사용하는 주소는 각각의 프로그램에 부여된 논리 주소
- CPU가 메모리와 상호작용하려면 논리 주소와 물리 주소 간의 변환이 이루어져야 함
- 논리 주소와 물리 주소 간의 변환은 CPU와 주소 버스 사이에 위치한 **메모리 관리 장치(MMU)** 라는 하드웨어에 의해 수행됨
- MMU는 CPU가 발생시킨 논리 주소에 베이스 레지스터 값을 더하여 논리 주소를 물리 주소로 변환
- **베이스 레지스터**는 프로그램의 가장 작은 물리 주소, 즉 프로그램의 첫 물리 주소를 저장하는 셈이며 **논리 주소**는 프로그램의 시작점으로부터 떨어진 거리인 셈

<br>

### 메모리 보호 기법
- 다른 프로그램의 영역을 침범할 수 있는 명령어는 위험하기 때문에 논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법 이 필요
  -> **한계 레지스터**가 담당
- 베이스 레지스터가 실행 중인 프로그램의 가장 작은 물리 주소를 저장한다면, 한계 레지스터는 논리 주소의 최대 크기를 저장
  - 즉, 프로그램의 물리 주소 범위는 베이스 레지스터 값 이상, 베이스 레지스터 값 + 한계 레지스터 값 미만이 됨
- CPU가 접근하려는 논리 주소는 한계 레지스터가 저장한 값보다 커서는 안됨
  - 한계 레지스터 보다 높은 주소 값에 접근하는 것은 곧 프로그램의 범위에 벗어난 메모리 공간에 접근하는 것과 같기 때문
- CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 항상 검사
- 만약 CPU가 한계 레지스터보다 높은 논리 주소에 접근하려고 하면 인터럽트(트랩)를 발생시켜 실행을 중단




<br><br><br>

## 06-3 캐시 메모리
### 저장 장치 계층 구조
- 저장 장치는 일반적으로 아래와 같은 명제를 따름
  ```
    1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
    2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.
  ```
- 저장 장치들의 장단점이 명확하여 일반적으로 컴퓨터는 다양한 저장 장치를 모두 사용
- 컴퓨터가 사용하는 저장 장치들은 ‘CPU에 얼마나 가까운가’를 기준으로 계층적으로 나타내는 것을 **저장 장치 계층 구조**라고 함
  <img src="https://github.com/Choi-Suhyeon/IoT_Project/assets/67042526/e1c21180-aa90-4140-ba19-f5b1486ba1fd"  width="450">

<br>

### 캐시 메모리
- CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치
- 캐시 메모리는 CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생
  - CPU가 매번 메모리에 왔다 갔다 하는 건 시간이 오래 걸리니, 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용
 
  <br>
    
  <img src="https://github.com/Choi-Suhyeon/IoT_Project/assets/67042526/624c4276-c687-4581-b50f-fb4bbc8d7aeb"  width="450">

- 컴퓨터 내부에는 여러 개의 캐시 메모리가 존재
- 캐시 메모리들은 CPU(코어)와 가까운 순서대로 계층을 구성
  - 코어와 가장 가까운 캐시 메모리를 L1 캐시, 그다음 가까운 캐시 메모리를 L2 캐시, 그다음 가까운 캐시 메모리를 L3 캐시라고 부름
  - 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치
- CPU가 메모리 내에 데이터가 필요하다고 판단하면 우선 L1 캐시에 해당 데이터가 있는지를 알아보고, 없다면 L2, L3 캐시 순으로 데이터를 검색
- 멀티 코어 프로세서에서 L1-L2-L3 캐시는 일반적으로 L1 캐시와 L2 캐시는 코어마다 고유한 캐시 메모리로 할당되고, L3 캐시는 여러 코어가 공유하는 형태로 사용
  ```
  +) 분리형 캐시
    - 코어와 가장 가까운 L1 캐시는 조금이라도 접근 속도를 빠르게 만들기 위해
      명령어만을 저장하는 L1 캐시인 L1I 캐시와 데이터만을 저장하는 L1 캐시인
      L1D 캐시로 분리하는 경우도 있음
  ```

<br>

### 참조 지역성 원리
- 보조기억장치는 전원이 꺼져도 기억할 대상을 저장하고, 메모리는 실행 중인 대상을 저장한다면 캐시 메모리는 CPU가 사용할 법한 대상을 예측하여 저장
- 이때 자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우를 **캐시 히트**라고 함
- 반대로 자주 사용될 것으로 예측하여 캐시 메모리에 저장했지만, 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우를 **캐시 미스**라고 함
- 캐시가 히트되는 비율을 **캐시 적중률**
  ```
    캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)
  ```
- 우리가 사용하는 컴퓨터의 캐시 적중률은 대략 85~95%
- 캐시 메모리는 참조 지역성의 원리에 따라 메모리로부터 가져올 데이터를 결정
- **참조 지역성의 원리**란 CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리
  ```
    1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다. -> 시간 지역성
    2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다. -> 공간 지역성
  ```
